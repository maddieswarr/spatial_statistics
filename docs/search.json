[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Geospatial Data Science in R",
    "section": "",
    "text": "Introduction",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#required-packages",
    "href": "index.html#required-packages",
    "title": "Geospatial Data Science in R",
    "section": "Required packages",
    "text": "Required packages\nThe following packages may be used during the course; it is assumed that you know how to install packages, and have permission to do so on your computer.\nR version\nWe require R 4.1.0 (as we’ll be using the native pipe |&gt;)\nCRAN packages:\n\ninstall.packages(c(\n\"sf\",\n\"stars\",\n\"terra\",\n\"s2\",\n\"gstat\",\n\"spatstat\",\n\"spdep\",\n\"spatialreg\",\n\"mgcv\"\n))\n\nnon-CRAN packages:\nr-inla: see https://www.r-inla.org/download-install\nstarsdata and spDataLarge:\n\noptions(timeout = 3600) # 1 hr instead of 1 min\ninstall.packages(\"spDataLarge\", repos = \"https://nowosad.github.io/drat/\", \n                 type = \"source\") # 23 Mb\ninstall.packages(\"starsdata\", repos = \"http://cran.uni-muenster.de/pebesma/\", \n                 type = \"source\") # 1 Gb\n\nIntroduction to the course\n\nintroduction of the tutor\nintroduction of course participants, please state\n\nname,\nwhere you’re from,\nwhich program you are in\n\n\nHow we work\nSessions are from 9:00-14:00 CET daily schedule:\n\n9:00 - 9:45 lecture block I\n10:00 - 10:45 lecture block II\n11:00 - 14:00 exercise block\n\nFurther:\n\nplease raise hands or speak up whenever something comes up\nplease share questions you run into in your actual research, preferably with (example) data and R code\nSyllabus\n\n\nday 1: the new spatial stack in R: simple features, DE-9IM, vector and raster data, data cubes; the spatial statistics data types\n\nday 2 operations, raster-vector, vector-raster: geometry measures, predicates, and transformers spherical geometry raster-vector: polygonizing, extracting vector-raster: rasterize, interpolate, density up- and down-scaling: aggregation, sampling, area-weighted interpolation, dasymetric mapping\n\nday 3. inference: spatial correlation, fitting models: spatial correlation for point patterns, geostatistical data, and lattice data fitting regression models under spatial correlation\n\nday 4 prediction and simulation; point patterns: fitting densities, simulating point patterns geostatistics: kriging interpolation, conditional simulation, simulating GMRFs\nResources\n\n\nSpatial Data Science: With applications in R, by Pebesma and Bivand 2023 (open online, hard copy from CRC)\nVignettes of sf: tab “Articles”\nVignettes of stars: tab “Articles”\nAll these material are written using quarto or R-markdown\n\nReading as preparation: students may want to read from this book chapters: 3-7, 10-12, 14-16",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#why-r-for-spatial-statistics-geospatial-data-science",
    "href": "index.html#why-r-for-spatial-statistics-geospatial-data-science",
    "title": "Geospatial Data Science in R",
    "section": "Why R for spatial statistics / geospatial data science?",
    "text": "Why R for spatial statistics / geospatial data science?\n\nR is old! Think of the advantages!\nR is as good as any data science language, but is more in focus with the statistical community\nMost researchers in spatial statistics who share code have used or use R\nR has a strong ecosystem of users and developers, who communicate and collaborate (and compete, mostly in a good way)\nR spatial packages have gone full cycle:\n\nthe first generation has been deprecated (rgdal, rgeos, maptools),\nthen removed from CRAN, and\nsuperseded by modern versions (sf and stars replaced sp, terra replaced raster)\n\n\nR is a data science language that allows you to work reproducibly\n\nBecause we have CRAN and CRAN Taskviews: Spatial, SpatioTemporal, Tracking\n\n\nReproducing or recreating the current course\n\nGo to https://github.com/edzer/madrid/\n\nGo to “Code”, then “copy URL to clipboard”\nClone this repo to your hard drive\nStart RStudio by double clickign the madrid.Rproj file in the source directory\nReproduce these course materials by installing quarto and\n\nin RStudio: run build - render book, or\non the command line: run quarto render in the course directory\n\n\nRun individual code sections in RStudio, and modify them!",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#exercises",
    "href": "index.html#exercises",
    "title": "Geospatial Data Science in R",
    "section": "Exercises",
    "text": "Exercises\n\nInstall the spDataLarge package (see instructions above)\nCopy (or clone) the course material from GitHub to your local machine\nOpen it in RStudio\nOpen the day1.qmd file. Try to identify a code chunk.\nRun the first code chunk.\nSkip to the last code chunk; run all code chunks above it (by a single click), and then run this last code chunk.\nRender the entire course “book”, view the result by opening _book/index.html in a web browser (from Rstudio)",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "day1.html",
    "href": "day1.html",
    "title": "\n1  The new spatial stack in R\n",
    "section": "",
    "text": "Learning goals",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The new spatial stack in R</span>"
    ]
  },
  {
    "objectID": "day1.html#what-is-special-about-spatial-data",
    "href": "day1.html#what-is-special-about-spatial-data",
    "title": "\n1  The new spatial stack in R\n",
    "section": "\n1.1 What is special about spatial data?",
    "text": "1.1 What is special about spatial data?\n\n\nLocation. Does location always involve coordinates? Relative/absolute, qualitative/quantitative\n\nCoordinates. What are coordinates? Dimension(s), unit\n\nTime. If not explicit, there is an implicit time reference. Dimension(s), unit, datetime\n\nAttributes. at specific locations we measure (observe) specific properties\nQuite often, we want to know where things change (space-time interactions).\n\nReference systems for space, time, and attributes: what are they?\n\nSupport: if we have an attribute value associated with a line, polygon or grid cell:\n\ndoes the value summarise all values at points? (line/area/cell support), or\n\nis the value constant throughout the line/area/cell (point support)?\n\n\n\nContinuity:\n\nis a variable spatially continuous? Yes for geostatistical data, no for point patterns\n\nis an attribute variable continuous? Stevens’s measurement scales: yes if Interval or Ratio.\n\n\n\nSupport: examples\n\nRoad properties\n\nroad type: gravel, brick, asphalt (point support: everywhere on the whole road)\nmean width: block support (summary value)\nminimum width: block support (although the minimum width may be the value at a single (point) location, it summarizes all widths of the road–we no longer know the width at any specific point location)\n\n\nLand use/land cover\n\nwhen we classify e.g. 30 m x 30 m Landsat pixels into a single class, this single class is not constant throughout this pixel\nroad type is a land cover type, but a road never covers a 30 m x 30 m pixel\na land cover type like “urban” is associated with a positive (non-point) support: we don’t say a point in a garden or park is urban, or a point on a roof, but these are part of a (block support) urban fabric\n\n\nElevation\n\nin principle, we can measure elevation at a point; in practice, every measuring device has a physical (non-point) size\n\n\nFurther reading: Chapter 5: Attributes and Support",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The new spatial stack in R</span>"
    ]
  },
  {
    "objectID": "day1.html#spatial-vs.-geospatial",
    "href": "day1.html#spatial-vs.-geospatial",
    "title": "\n1  The new spatial stack in R\n",
    "section": "\n1.2 Spatial vs. Geospatial",
    "text": "1.2 Spatial vs. Geospatial\n\nSpatial refers (physical) spaces, 2- or 3-dimensional (\\(R^2\\) or \\(R^3\\))\n\nMost often spatial statistics considers 2-dimensional problems\n3-d: meteorology, climate science, geophysics, groundwater hydrology, aeronautics, …\nwith time: spatiotemporal, this becomes 3- or 4-dimensional (\\(R^3\\) or \\(R^4\\))\n\n\n“Geo” refers to the Earth\nFor Earth coordinates, we always need a datum, consisting of an ellipsoid (shape) and the way it is fixed to the Earth (origin)\n\nThe Earth is modelled by an ellipsoid, which is nearly round\nIf we consider Earth-bound areas as flat, for larger areas we get the distances wrong\nWe can (and do) also work on \\(S^2\\), the surface of a sphere, rather than \\(R^2\\), to get distances right, but this creates a number of challenges (such as plotting on a 2D device)\n\n\nNon-geospatial spaces could be:\n\nAssociated with other bodies (moon, Mars: similar “size”)\nAstrophysics, places/directions in the universe (different size/scale)\nLocations in a building (where we use “engineering coordinates”, relative to a building corner and orientation) (different size/scale)\nMicroscope images (different size/scale)\nMRT scans (3-D), places in a human body (different size/scale)\nlocations on a genome? (different size/scale)\n\n\n\n\nCodelibrary(rnaturalearth)\nlibrary(sf)\n# Linking to GEOS 3.12.1, GDAL 3.8.4, PROJ 9.4.0; sf_use_s2() is TRUE\npar(mar = c(2,2,0,0) + .1)\nne_countries() |&gt; st_geometry() |&gt; plot(axes=TRUE)\n\n\n\nworld map, with longitude and latitude map linearly to x and y (Plate Caree): does the Earth look like this?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The new spatial stack in R</span>"
    ]
  },
  {
    "objectID": "day1.html#simple-features",
    "href": "day1.html#simple-features",
    "title": "\n1  The new spatial stack in R\n",
    "section": "\n1.3 Simple features",
    "text": "1.3 Simple features\n“Simple features” comes from simple feature access, an OGC standard. OGC stands for “Open Geospatial Consortium” and is a standardisation body; many OGC standards become ISO standards (for whatever it is worth!).\nA feature is a “thing” that has\n\na feature geometry (location, shape if not point)\nother properties, called feature attributes\n\n“Simple” in “simple feature” refers to the property that geometries are points, lines or polygons, and that lines and polygon boundaries consists of sequences of points connected with straight lines (edges), and that edges do not cross other edges (do not self-intersect). Polygons consist of an outer (closed) ring with zero or more inner (closed) rings denoting holes.\nSimple feature geometries are zero-dimensional (points), one-dimensional (linestrings), or two-dimensional (polygons). Each geometry has an interior (I), a boundary (B) and an exterior (E). For polygons this is trivial, but\n\npoints: have an interior but no boundary\nlines: have a boundary that consists of the end points, all other points are interior\n\nIntro to sf and stars\n\n\nBriefly: sf provides classes and methods for simple features\n\na feature is a “thing”, with geometrical properties (point(s), line(s), polygon(s)) and attributes\n\nsf stores data in data.frames with a list-column (of class sfc) that holds the geometries\n\n\n\n\n\n\n\n\n\nthe Simple Feature standard\n\n\n\n“Simple Feature Access” is an open standard for data with vector geometries. It defines a set of classes for geometries and operations on them.\n\n“simple” refers to curves that are “simply” represented by points connected by straight lines\nconnecting lines are not allowed to self-intersect\n\npolygons can have holes, and have validity constraints: holes cannot extrude the outer ring etc.\nAll spatial software uses this: ArcGIS, QGIS, PostGIS, other spatial databases, …\n\n\n\nWhy do all functions in sf start with st_?\n\nsee here\n\n\nsf operators, how to understand?\nPackage sf has objects at three nested “levels”:\n\nsfg: a single geometry (without coordinate reference system); contained in:\nsfc: a set of sfg geometries (list), with a coordinate reference system and bounding box; contained in:\nsf: a data.frame or tibble with at least one geometry (sfc) column\n\nOperations not involving geometry (data.frame; base R; tidyverse)\n\ngeometry column + sf class is sticky!\nthis can be convenient, and sometimes annoying\nuse as.data.frame or as_tibble to strip the sf class label\n\n\n\nOperations involving only geometry\n\n\npredicates (resulting TRUE/FALSE)\n\nunary\nbinary: DE9-IM; work on two sets, result sgbp, which is a sparse logical matrix representation\n\nis_within_distance\n\n\n\n\n\nmeasures\n\nunary: length, area\nbinary: distance, by_element = FALSE\n\n\n\n\ntransformers\n\nunary: buffer, centroid\nbinary: intersection, union, difference, symdifference\nn-ary: intersection, difference\n\n\n\n\n\nOperations involving geometry and attributes\n\nmany of the above!\nst_join\naggregate\n\nst_interpolate_aw: requires expression whether variable is spatially extensive or intensive\n\n\n\n\nsf and spatstat\n\nWe can try to convert an sf object to a ppp (point pattern object in spatstat):\n\nlibrary(sf)\nlibrary(spatstat)\n# Loading required package: spatstat.data\n# Loading required package: spatstat.univar\n# spatstat.univar 3.1-1\n# Loading required package: spatstat.geom\n# spatstat.geom 3.3-4\n# Loading required package: spatstat.random\n# spatstat.random 3.3-2\n# Loading required package: spatstat.explore\n# Loading required package: nlme\n# spatstat.explore 3.3-4\n# Loading required package: spatstat.model\n# Loading required package: rpart\n# spatstat.model 3.3-3\n# Loading required package: spatstat.linnet\n# spatstat.linnet 3.2-3\n# \n# spatstat 3.3-0 \n# For an introduction to spatstat, type 'beginner'\ndemo(nc, echo = FALSE, ask = FALSE)\npts = st_centroid(st_geometry(nc))\nas.ppp(pts) # ???\n# Error: Only projected coordinates may be converted to spatstat\n# class objects\n\nNote that sf interprets a NA CRS as: flat, projected (Cartesian) space.\nstars\nPackages stars is a package for (dense) array data, where array dimensions are associated with space and/or time (spatial time series, data cubes). It is built for simplicity (pure R), and for maximum integration with sf.\nR’s array is very powerful, but its metadata (dimnames) is restricted to character vectors.\nA stars object\n\nis a list with R arrays (or pointers to files with such arrays)\nhas a dimensions attribute with all the metadata of the dimensions (offset, cellsize, units, reference system, point/block support)\n\n\nlibrary(stars)\n# Loading required package: abind\nst_as_stars() # default: 1 degree global Cartesian grid\n# stars object with 2 dimensions and 1 attribute\n# attribute(s):\n#         Min. 1st Qu. Median Mean 3rd Qu. Max.\n# values     0       0      0    0       0    0\n# dimension(s):\n#   from  to offset delta         refsys x/y\n# x    1 360   -180     1 WGS 84 (CRS84) [x]\n# y    1 180     90    -1 WGS 84 (CRS84) [y]\n\nValid polygons\nValid polygons are polygons with several geometrical constraints, such as\n\na closed ring means the first and last coordinate are identical,\nno edge is traversed twice,\na hole can touch an outer ring only in a point, not along a line(string)\nholes are inside the outer ring\nouter rings are winded counter-clockwise (CCW), inner rings (holes) clockwise (CW)\n\nIn particular the last condition is often dropped, as the order of the rings already denotes their role, and winding can easily reversed. An exception of this is polygons on the sphere, where both inside and outside have a limited area.\nDE-9IM: dimensionally extended nine-intersection model\nThe intersection of two geometries is the set of points they have in common. This set can be empty (no points), 0-, 1-, or 2-dimensional. The DE-9IM defines the relation between two geometries as the intersection of I, B and E of the first and the second geometry (hence: 9, see https://r-spatial.org/book/03-Geometries.html#fig-de9im). The values can be F (empty), 0, 1 or 2 (dimension if not empty), or T (not empty: any of 0, 1 or 2). Using the resulting encoding (the relation), one can define special predicates, such as\n\nA covers B\nA contains B\nA is disjoint from B\nA equals B\n\nand many more on; one can also define custom queries with a specific pattern, e.g.:\n\nA relates to B according to pattern 0FFFFFFF2.\nDE9-IM: challenges\nWe often work with polygon data that form a polygon coverage, which is a tesselation of an area of interest, e.g.\n\ncountries in a continent,\nprovinces in a country,\ncounties in a province\n\nWhen representing the polygons as a set of outer rings, it is hard to see whether there are no overlaps, and no gaps between polygons. Such overlaps or gaps could result from generalisation of polygon boundaries, one-by-one, and not by first identifying a common boundary and then generalizing that.\n“True” geographic information systems (e.g. ArcGIS or GRASS GIS) use a topological representation of geometries that consists of edge nodes and (outer and inner) boundaries, and can do such simplifications without creating overlaps or gaps.\nAnother challenge is that polygon coverages represented as a set of simple feature polygons do not uniquely assign all points to a single unit. Points on a boundary common to two geometries intersect with both, there is no geometric argument to assign them unambiguously to only one of them.\nFinally, as the Earth is round, the use of straight lines is problematic:\n\nprojection or re-projection changes space non-linearly, causing a straight line to change path\nunprojected data are associated with a sphere (or ellipsoid), leading to options what “straight” means, e.g.\n\nGeoJSON defines straight lines as straight in Plate Carree\ns2geometry assumes great circle segments\n\n\nvector and raster data\nIn addition to vector (point/line/polygon) data, we also have raster data. For regular rasters, space is cut into square cells, aligned with \\(x\\) and \\(y\\). Raster spaces can tesselate, see here.\nIn addition to regular rasters, we have rotated, sheared, rectilinear and curvilinear rasters. The raster space is primarily flat, so any time we use it model data of the Earth surface, we violate the constant raster cell size concept. Many data are distributed as regular rasters in geodetic coordinates (long/lat space, e.g., 0.25 degree raster cells), mostly for convienience (of who?)\nDiscrete global grids are (semi-)regular tesselations of the Earth surface, using squares, triangles, or hexagons. Examples are:\n\nGoogle’s s2geometry (R package s2)\nUber’s H3 (R package h3r)\nKevin Sahr’s dggrid (also nested hexagons; R package dggridr)\n\nInterestingly, computer screens are raster devices, so any time we do view vector data on a computer screen, a rasterization has taken place.\ndata cubes\nData cubes are array data with one or more dimensions associated with space or geometry. The degenerate example is a one-dimensional array (or collection thereof), which we have in a table or data.frame. The canonical example of array data is raster data, or a time series thereof.\nFurther examples include:\n\n3D rasters, including depth/height (atmospheric, geological)\ntime series for points (one dimension with feature geometries)\ntime series for areas (one dimension with feature geometries)\nOrigin-destination (OD) matrices (two dimensions with feature geometries)\nOD matrices as a function of time",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The new spatial stack in R</span>"
    ]
  },
  {
    "objectID": "day1.html#the-spatial-statistics-data-types",
    "href": "day1.html#the-spatial-statistics-data-types",
    "title": "\n1  The new spatial stack in R\n",
    "section": "\n1.4 The spatial statistics data types",
    "text": "1.4 The spatial statistics data types\nPoint Patterns\n\nPoints (locations) + observation window\nExample from here\n\n\n\n\n\n\n\n\n\nFigure 1.1: Wind turbine parks in Germany\n\n\n\n\n\nThe locations contain the information\nPoints may have (discrete or continuous) marks (attributes)\nThe observation window tells where there are no points (empty space)\nGeostatistical data: locations + measured values\n\nCodelibrary(sf)\nno2 &lt;- read.csv(system.file(\"external/no2.csv\",\n    package = \"gstat\"))\ncrs &lt;- st_crs(\"EPSG:32632\")\nst_as_sf(no2, crs = \"OGC:CRS84\", coords =\n    c(\"station_longitude_deg\", \"station_latitude_deg\")) |&gt;\n    st_transform(crs) -&gt; no2.sf\nlibrary(ggplot2)\n# plot(st_geometry(no2.sf))\nread_sf(\"de_nuts1.gpkg\") |&gt;\n  st_transform(crs) -&gt; de\nggplot() + geom_sf(data = de) +\n    geom_sf(data = no2.sf, mapping = aes(col = NO2))\n\n\n\nNO2 measurements at rural background stations (EEA)\n\n\n\n\nThe value of interest is measured at a set of sample locations\nAt other location, this value exists but is missing\n\nThe interest is in estimating (predicting) this missing value (interpolation)\nThe actual sample locations are not of (primary) interest, the signal is in the measured values\nAreal data\n\npolygons (or grid cells) + polygon summary values\n\n\nCode# https://en.wikipedia.org/wiki/List_of_NUTS_regions_in_the_European_Union_by_GDP\nde$GDP_percap = c(45200, 46100, 37900, 27800, 49700, 64700, 45000, 26700, 36500, 38700, 35700, 35300, 29900, 27400, 32400, 28900)\nggplot() + geom_sf(data = de) +\n    geom_sf(data = de, mapping = aes(fill = GDP_percap)) + \n    geom_sf(data = st_cast(de, \"MULTILINESTRING\"), col = 'white')\n\n\n\nNO2 rural background, average values per NUTS1 region\n\n\n\n\nThe polygons contain polygon summary (polygon support) values, not values that are constant throughout the polygon (as in a soil, lithology or land cover map)\nNeighbouring polygons are typically related: spatial correlation\nneighbour-neighbour correlation: Moran’s I\nregression models with correlated errors, spatial lag models, CAR models, GMRFs, …\nsee Ch 14-17 of SDSWR\n\nbriefly addressed on Friday",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The new spatial stack in R</span>"
    ]
  },
  {
    "objectID": "day1.html#data-types-that-received-less-attention-in-the-spatial-statistics-literature",
    "href": "day1.html#data-types-that-received-less-attention-in-the-spatial-statistics-literature",
    "title": "\n1  The new spatial stack in R\n",
    "section": "\n1.5 Data types that received less attention in the spatial statistics literature",
    "text": "1.5 Data types that received less attention in the spatial statistics literature\nImage data\n\nCodelibrary(stars)\nplot(L7_ETMs, rgb = 1:3)\n\n\n\nRGB image from a Landsat scene\n\n\n\n\nare these geostatistical data, or areal data?\nIf we identify objects from images, can we see them as point patterns?\nTracking data, trajectories\n\nCode# from: https://r-spatial.org/r/2017/08/28/nest.html\nlibrary(tidyverse)\n# ── Attaching core tidyverse packages ──────────── tidyverse 2.0.0 ──\n# ✔ dplyr     1.1.4     ✔ readr     2.1.5\n# ✔ forcats   1.0.0     ✔ stringr   1.5.1\n# ✔ lubridate 1.9.4     ✔ tibble    3.2.1\n# ✔ purrr     1.0.2     ✔ tidyr     1.3.1\n# ── Conflicts ────────────────────────────── tidyverse_conflicts() ──\n# ✖ dplyr::collapse() masks nlme::collapse()\n# ✖ dplyr::filter()   masks stats::filter()\n# ✖ dplyr::lag()      masks stats::lag()\n# ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nstorms.sf &lt;- storms %&gt;%\n    st_as_sf(coords = c(\"long\", \"lat\"), crs = 4326)\nstorms.sf &lt;- storms.sf %&gt;% \n    mutate(time = as.POSIXct(paste(paste(year,month,day, sep = \"-\"), \n                                   paste(hour, \":00\", sep = \"\")))) %&gt;% \n    select(-month, -day, -hour)\nstorms.nest &lt;- storms.sf %&gt;% group_by(name, year) %&gt;% nest\nto_line &lt;- function(tr) st_cast(st_combine(tr), \"LINESTRING\") %&gt;% .[[1]] \ntracks &lt;- storms.nest %&gt;% pull(data) %&gt;% map(to_line) %&gt;% st_sfc(crs = 4326)\nstorms.tr &lt;- storms.nest %&gt;% select(-data) %&gt;% st_sf(geometry = tracks)\nstorms.tr %&gt;% ggplot(aes(color = year)) + geom_sf()\n\n\n\nStorm/hurricane trajectories colored by year\n\n\n\n\nA temporal snapshot (time slice) of a set of moving things forms a point pattern\nWe often analyse trajectories by\n\nestimating densities, for space-time blocks, per individual or together\nanalysing interactions (alibi problem, mating animals, home range, UDF etc)\n\n\nDesign-based statistics\nIn design-based statistics, randomness comes from random sampling. Consider an area \\(B\\), from which we take samples \\[z(s),\ns \\in B,\\] with \\(s\\) a location for instance two-dimensional: \\(s_i =\n\\{x_i,y_i\\}\\). If we select the samples randomly, we can consider \\(S \\in B\\) a random variable, and \\(z(S)\\) a random sample. Note the randomness in \\(S\\), not in \\(z\\).\nTwo variables \\(z(S_1)\\) and \\(z(S_2)\\) are independent if \\(S_1\\) and \\(S_2\\) are sampled independently. For estimation we need to know the inclusion probabilities, which need to be non-negative for every location.\nIf inclusion probabilities are constant (simple random sampling; or complete spatial randomness: day 2, point patterns) then we can estimate the mean of \\(Z(B)\\) by the sample mean \\[\\frac{1}{n}\\sum_{j=1}^n\nz(s_j).\\] This also predicts the value of a randomly chosen observation \\(z(S)\\). It cannot be used to predict the value \\(z(s_0)\\) for a non-randomly chosen location \\(s_0\\); for this we need a model.\nModel-based statistics\nModel-based statistics assumes randomness in the measured responses; consider a regression model \\(y = X\\beta + e\\), where \\(e\\) is a random variable and as a consequence \\(y\\), the response variable is a random variable. In the spatial context we replace \\(y\\) with \\(z\\), and capitalize it to indicate it is a random variable, and write \\[Z(s) = X(s)\\beta + e(s)\\] to stress that\n\n\n\\(Z(s)\\) is a random function (random variables \\(Z\\) as a function of \\(s\\))\n\n\\(X(s)\\) is the matrix with covariates, which depend on \\(s\\)\n\n\n\\(\\beta\\) are (spatially) constant coefficients, not depening on \\(s\\)\n\n\n\\(e(s)\\) is a random function with mean zero and covariance matrix \\(\\Sigma\\)\n\n\nIn the regression literature this is called a (linear) mixed model, because \\(e\\) is not i.i.d. If \\(e(s)\\) contains an iid component \\(\\epsilon\\) we can write this as\n\\[Z(s) = X(s)\\beta + w(s) + \\epsilon\\]\nwith \\(w(s)\\) the spatial signal, and \\(\\epsilon\\) a noise compenent e.g. due to measurement error.\nPredicting \\(Z(s_0)\\) will involve (GLS) estimation of \\(\\beta\\), but also prediction of \\(e(s_0)\\) using correlated, nearby observations (day 3: geostatistics).\nDesign- or model-based?\n\ndesign-based requires a random sample, if that is the case it needs no further assumptions\nmodel-based requires stationarity assumptions to estimate \\(\\Sigma\\)\n\nmodel-based is typically more effective for interpolation problems\ndesign-based can be most effective when estimating, e.g. average mapping errors",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The new spatial stack in R</span>"
    ]
  },
  {
    "objectID": "day1.html#checklist-if-you-have-spatial-data",
    "href": "day1.html#checklist-if-you-have-spatial-data",
    "title": "\n1  The new spatial stack in R\n",
    "section": "\n1.6 Checklist if you have spatial data",
    "text": "1.6 Checklist if you have spatial data\n\nDo you have the spatial coordinates of your data?\nAre the coordinates Earth-bound?\nIf yes, do you have the coordinate reference system of them?\nWhat is the support (physical size) of your observations?\nWere the data obtained by random sampling, and if yes, do you have sampling weights?\nDo you know the extent from which your data were sampled, or collected?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The new spatial stack in R</span>"
    ]
  },
  {
    "objectID": "day1.html#exercises",
    "href": "day1.html#exercises",
    "title": "\n1  The new spatial stack in R\n",
    "section": "\n1.7 Exercises",
    "text": "1.7 Exercises\n\nWhat is the coordinate reference system of the ne_countries() dataset, imported above?\nLook up the “Equidistant Cylindrical (Plate Carrée)” projection on the https://proj.org website.\nWhy is this projection called The simplest of all projections?\nProject ne_countries to Plate Carrée, and plot it with axes=TRUE. What has changed? (Hint: st_crs() accepts a proj string to define a coordinate reference system (CRS); st_transform() transforms a dataset to a new CRS.)\nProject the same dataset to Eckert IV projection. What has changed?\nAlso try plotting this dataset after transforming it to an orthographic projection with +proj=ortho; what went wrong?\n\nNext: continue with the exercises of Chapter 3 of “Spatial Data Science: with applications in R”, then those of Chapter 6.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The new spatial stack in R</span>"
    ]
  },
  {
    "objectID": "day1.html#further-reading",
    "href": "day1.html#further-reading",
    "title": "\n1  The new spatial stack in R\n",
    "section": "\n1.8 Further reading",
    "text": "1.8 Further reading\n\nRipley, B. 1981. Spatial Statistics. Wiley.\nCressie, N. 1993. Statistics for Spatial Data. Wiley.\nCochran, W.G. 1977. Sampling Techniques. Wiley.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The new spatial stack in R</span>"
    ]
  },
  {
    "objectID": "day2.html",
    "href": "day2.html",
    "title": "\n2  Operations, raster-vector, vector-raster\n",
    "section": "",
    "text": "2.1 Learning goals\nIn many practical geospatial data science cases, the researcher is faced with combining different datasets that multiple include datasets\nA common approach is to first work all datasets towards a common reference system, type, and resolution, and then combine them. What the “best” common resolution is depends on the goals of the study. Today we will look at methods and tools to do so.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Operations, raster-vector, vector-raster</span>"
    ]
  },
  {
    "objectID": "day2.html#learning-goals",
    "href": "day2.html#learning-goals",
    "title": "\n2  Operations, raster-vector, vector-raster\n",
    "section": "",
    "text": "of raster and vector type,\nwith different spatial coordinate systems\nwith different time reference\nwith different spatial and/or temporal resolutions\n\n\n\n\n\n\n\n\nSummary\n\n\n\n\nUpstream libraries\nOperatios on vector data and on raster data\nVector-raster and raster-vector conversions\nUp- and downsampling, area-weighted interpolation",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Operations, raster-vector, vector-raster</span>"
    ]
  },
  {
    "objectID": "day2.html#the-upstream-libraries",
    "href": "day2.html#the-upstream-libraries",
    "title": "\n2  Operations, raster-vector, vector-raster\n",
    "section": "\n2.2 The upstream libraries",
    "text": "2.2 The upstream libraries\nThe main libraries: GDAL, PROJ and GEOS are found in all spatial data science software stacks. See here for R; for R and Python below:\n\n\n\n\n\n\n\nFigure 2.1",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Operations, raster-vector, vector-raster</span>"
    ]
  },
  {
    "objectID": "day2.html#geometry-measures-predicates-and-transformers",
    "href": "day2.html#geometry-measures-predicates-and-transformers",
    "title": "\n2  Operations, raster-vector, vector-raster\n",
    "section": "\n2.3 geometry measures, predicates, and transformers",
    "text": "2.3 geometry measures, predicates, and transformers\nmeasaures\nGeometry measures include\n\nunary measures: area, length, dimension\nbinary measures: distance (and relate, which gives the DE9-IM pattern)\npredicates\nPredicates include those in this table.\ntransformers\nSee unary and binary and n-ary for a full list.\n\nlibrary(sf)\n# Linking to GEOS 3.12.1, GDAL 3.8.4, PROJ 9.4.0; sf_use_s2() is TRUE\npt = st_point(c(0,0))\nb = st_buffer(pt, 1)\nplot(b)\nplot(pt, add = TRUE, cex = 3, col = 'red', pch = 3)\n\n\n\n\n\n\nst_area(b)\n# [1] 3.14\npi - st_area(b) # why not zero?\n# [1] 0.00144\n\n\npt2 = st_point(c(1.5, 0))\nb1 = st_buffer(pt, 1)\nb2 = st_buffer(pt2, 1)\npar(mfrow = c(2, 2), mar = c(0,0,1,0))\nplot(c(b1, b2), main = 'union')\nplot(st_union(b1, b2), col = 'lightgrey', add = TRUE)\nplot(c(b1, b2), add = TRUE)\nplot(c(b1, b2), main = 'intersection')\nplot(st_intersection(b1, b2), col = 'lightgrey', add = TRUE)\nplot(c(b1, b2), add = TRUE)\nplot(c(b1, b2), main = 'difference')\nplot(st_difference(b1, b2), col = 'lightgrey', add = TRUE)\nplot(c(b1, b2), add = TRUE)\nplot(c(b1, b2), main = 'sym_difference')\nplot(st_sym_difference(b1, b2), col = 'lightgrey', add = TRUE)\nplot(c(b1, b2), add = TRUE)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Operations, raster-vector, vector-raster</span>"
    ]
  },
  {
    "objectID": "day2.html#spherical-geometry",
    "href": "day2.html#spherical-geometry",
    "title": "\n2  Operations, raster-vector, vector-raster\n",
    "section": "\n2.4 spherical geometry",
    "text": "2.4 spherical geometry\nAll software using GEOS (Python, PostGIS, QGIS) computes geometrical operations on geodetic (long/lat) coordinates in \\(R^2\\) - in a flat, Cartesian coordinate system. Python’s geopandas warns if it does, but does it nevertheless. In R’s sf we can mimic this by setting sf_use_s2(FALSE).\n\nold = sf_use_s2(FALSE)\n# Spherical geometry (s2) switched off\np1 = st_sfc(st_point(c(0, 0)), crs = 'OGC:CRS84')\np2 = st_sfc(st_point(c(0,40)), crs = 'OGC:CRS84')\nb1 = st_buffer(p1, 10) \n# Warning in st_buffer.sfc(p1, 10): st_buffer does not correctly\n# buffer longitude/latitude data\n# dist is assumed to be in decimal degrees (arc_degrees).\nb1 |&gt; st_area() |&gt; units::set_units(km^2)\n# 3850972 [km^2]\nb2 = st_buffer(p2, 10) \n# Warning in st_buffer.sfc(p2, 10): st_buffer does not correctly\n# buffer longitude/latitude data\n# dist is assumed to be in decimal degrees (arc_degrees).\nb2 |&gt; st_area() |&gt; units::set_units(km^2)\n# 2965892 [km^2]\nsf_use_s2(old) # restore\n# Spherical geometry (s2) switched on\n\nBoth buffers “look” good in plate carree:\n\nlibrary(sf)\nlibrary(rnaturalearth)\npar(mar = c(2,2,0,0) + .1)\nne_countries() |&gt; st_geometry() |&gt; plot(axes=TRUE)\nplot(b1, add = TRUE, border = 'red')\nplot(b2, add = TRUE, border = 'red')\n\n\n\n\n\n\n\nbut not on a plot with proper aspect ratio:\n\nplot(b2)\nne_countries() |&gt; st_geometry() |&gt; plot(axes=TRUE, add=TRUE)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Operations, raster-vector, vector-raster</span>"
    ]
  },
  {
    "objectID": "day2.html#raster-vector-polygonizing-extracting",
    "href": "day2.html#raster-vector-polygonizing-extracting",
    "title": "\n2  Operations, raster-vector, vector-raster\n",
    "section": "\n2.5 raster-vector: polygonizing, extracting",
    "text": "2.5 raster-vector: polygonizing, extracting\nRasters can be converted to vector data, either cell-by-cell or groupwise. Cell-by-cell one could convert to either points or polygons:\n\nlibrary(stars)\n# Loading required package: abind\nL7 = st_as_stars(L7_ETMs)\nL7[,1:30,1:30] |&gt; st_as_sf(as_points = TRUE) |&gt; plot(cex = .75, pch = 16, key.pos = 1)\n\n\n\n\n\n\nL7[,1:30,1:30] |&gt; st_as_sf(as_points = FALSE) |&gt; plot(key.pos = 1)\n\n\n\n\n\n\n\nIf we have categorical variables in a raster map, such as land use, we can create contiguous polygons from areas having a constant value:\n\nlc = read_stars(system.file(\"tif/lc.tif\", package = \"stars\"))\nplot(lc, key.pos = 4, key.width = lcm(7))\n\n\n\n\n\n\npal = attr(lc[[1]], \"colors\")\nst_as_sf(lc, merge = TRUE) |&gt; plot(key.pos = 4, pal = pal, key.width = lcm(7))\n\n\n\n\n\n\n\nRaster values can be extracted at arbitrary point locations:\n\nset.seed(131) # to make this reproducible\npts.L7 = st_sample(st_bbox(L7), 3)\nst_extract(L7, pts.L7) # two-dimensional array: 3 points x 6 bands\n# stars object with 2 dimensions and 1 attribute\n# attribute(s):\n#          Min. 1st Qu. Median Mean 3rd Qu. Max.\n# L7_ETMs    26      48     61 62.7    72.8  121\n# dimension(s):\n#          from to            refsys point\n# geometry    1  3 SIRGAS 2000 / ...  TRUE\n# band        1  6                NA    NA\n#                                           values\n# geometry POINT (290830 ...,...,POINT (291693 ...\n# band                                        NULL\nst_extract(L7, pts.L7) |&gt; st_as_sf() # \"wide\": bands spread over columns\n# Simple feature collection with 3 features and 6 fields\n# Geometry type: POINT\n# Dimension:     XY\n# Bounding box:  xmin: 290000 ymin: 9110000 xmax: 292000 ymax: 9120000\n# Projected CRS: SIRGAS 2000 / UTM zone 25S\n#   L7_ETMs.V1 L7_ETMs.V2 L7_ETMs.V3 L7_ETMs.V4 L7_ETMs.V5 L7_ETMs.V6\n# 1         80         66         71         59        121         94\n# 2         58         41         29         76         56         26\n# 3         63         51         45         72         73         47\n#                 geometry\n# 1 POINT (290830 9114499)\n# 2 POINT (290019 9119219)\n# 3 POINT (291693 9116038)\nst_extract(L7, pts.L7) |&gt; st_as_sf(long = TRUE) # \"long form\": cycles geometries\n# Simple feature collection with 18 features and 2 fields\n# Geometry type: POINT\n# Dimension:     XY\n# Bounding box:  xmin: 290000 ymin: 9110000 xmax: 292000 ymax: 9120000\n# Projected CRS: SIRGAS 2000 / UTM zone 25S\n# First 10 features:\n#    band L7_ETMs               geometry\n# 1     1      80 POINT (290830 9114499)\n# 2     1      58 POINT (290019 9119219)\n# 3     1      63 POINT (291693 9116038)\n# 4     2      66 POINT (290830 9114499)\n# 5     2      41 POINT (290019 9119219)\n# 6     2      51 POINT (291693 9116038)\n# 7     3      71 POINT (290830 9114499)\n# 8     3      29 POINT (290019 9119219)\n# 9     3      45 POINT (291693 9116038)\n# 10    4      59 POINT (290830 9114499)\npts.lc = st_sample(st_bbox(lc), 7)\nst_extract(lc, pts.lc) |&gt; na.omit() # one-dimensional: returns an `sf` object by default\n# Simple feature collection with 4 features and 1 field\n# Geometry type: POINT\n# Dimension:     XY\n# Bounding box:  xmin: 3150000 ymin: -38300 xmax: 3220000 ymax: 16200\n# Projected CRS: Albers Conical Equal Area\n#                        lc.tif               geometry\n# 1            Cultivated Crops POINT (3223109 -34971)\n# 2            Evergreen Forest  POINT (3152354 -6395)\n# 3 Developed, Medium Intensity POINT (3174647 -38344)\n# 5                 Herbaceuous  POINT (3197310 16231)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Operations, raster-vector, vector-raster</span>"
    ]
  },
  {
    "objectID": "day2.html#vector-raster-rasterize-interpolate-density",
    "href": "day2.html#vector-raster-rasterize-interpolate-density",
    "title": "\n2  Operations, raster-vector, vector-raster\n",
    "section": "\n2.6 vector-raster: rasterize, interpolate, density",
    "text": "2.6 vector-raster: rasterize, interpolate, density\nrasterize\n\nde.sf = read_sf(\"de_nuts1.gpkg\")\nde.sf$HASC_1.f = as.factor(de.sf$HASC_1)\nplot(de.sf[\"HASC_1.f\"])\n\n\n\n\n\n\nplot(st_as_stars(de.sf[\"HASC_1.f\"])) # vector data cube\ntemplate = st_as_stars(st_bbox(de.sf), dx = 0.1) # .1 x .1 degree cells\nde.r = st_rasterize(de.sf[\"HASC_1.f\"], template) \nplot(de.r)\n\n\n\n\n\n\n\nst_rasterize() calls the GDAL utility gdal_rasterize (through the C API, not as as system call). Its command line options are found here. E.g., to fill all cells touched by a polygon, rather than those which a pixel center in a polygon, we can use\n\nde.r$at = st_rasterize(de.sf[\"HASC_1.f\"], template, options = \"ALL_TOUCHED=TRUE\")\nde.r\n# stars object with 2 dimensions and 2 attributes\n# attribute(s):\n#    HASC_1.f          at       \n#  DE.BY  : 868   DE.BY  : 929  \n#  DE.NI  : 639   DE.NI  : 648  \n#  DE.NW  : 446   DE.NW  : 499  \n#  DE.BW  : 441   DE.BW  : 421  \n#  DE.BR  : 393   DE.MV  : 380  \n#  DE.MV  : 305   DE.BR  : 360  \n#  (Other):1497   (Other):1705  \n# dimension(s):\n#   from to offset delta refsys point x/y\n# x    1 92   5.87   0.1 WGS 84 FALSE [x]\n# y    1 78   55.1  -0.1 WGS 84 FALSE [y]\nas.vector(de.r$at) |&gt; length() # nr of non-missing values\n# [1] 4942\nas.vector(de.r$HASC_1.f) |&gt; length()\n# [1] 4589\n\nSee ?gdal_utils for help on other GDAL utilities available through the C API.\nInterpolate and density\nInterpolating measured values, or estimating densities of points are two common methods to move from point data to continuous rasters. We will use the NO2 dataset over Germany, and work in a sensible coordinate reference system (UTM zone 32N):\nInterpolation (inverse distance):\n\nno2 &lt;- read.csv(system.file(\"external/no2.csv\", package = \"gstat\"))\ncrs &lt;- st_crs(\"EPSG:32632\")\nst_as_sf(no2, crs = \"OGC:CRS84\", coords =\n    c(\"station_longitude_deg\", \"station_latitude_deg\")) |&gt;\n    st_transform(crs) -&gt; no2.sf\nde.sf |&gt; st_transform(crs) -&gt; de\ntemplate = st_as_stars(st_bbox(de), dx = units::set_units(10, km)) # 10 km x 10 km\nde.r_utm = st_rasterize(de[\"HASC_1.f\"], template) \nde.r_utm$mask = ifelse(as.numeric(de.r_utm[[1]]) == 0, NA, 1)\nlibrary(gstat)\nno2.r = gstat::idw(NO2~1, no2.sf, de.r_utm[\"mask\"])\n# [inverse distance weighted interpolation]\nplot(no2.r[\"var1.pred\"], reset = FALSE, breaks = \"equal\", main = \"NO2 conc.\")\nst_geometry(no2.sf) |&gt; plot(add = TRUE, col = 'green', pch = 16)\nst_geometry(de) |&gt; plot(add = TRUE, border = \"yellow\")\n\n\n\n\n\n\n\nPoint densities:\n\nlibrary(spatstat)\n# Loading required package: spatstat.data\n# Loading required package: spatstat.univar\n# spatstat.univar 3.1-1\n# Loading required package: spatstat.geom\n# spatstat.geom 3.3-4\n# Loading required package: spatstat.random\n# spatstat.random 3.3-2\n# Loading required package: spatstat.explore\n# Loading required package: nlme\n# spatstat.explore 3.3-4\n# \n# Attaching package: 'spatstat.explore'\n# The following object is masked from 'package:gstat':\n# \n#     idw\n# Loading required package: spatstat.model\n# Loading required package: rpart\n# spatstat.model 3.3-3\n# Loading required package: spatstat.linnet\n# spatstat.linnet 3.2-3\n# \n# spatstat 3.3-0 \n# For an introduction to spatstat, type 'beginner'\nd = density(as.ppp(no2.sf[\"NO2\"], as.owin(de))) |&gt; st_as_stars()\nplot(d, reset = FALSE, main = \"station density\")\nst_geometry(no2.sf) |&gt; plot(add = TRUE, col = 'green', pch = 16)\nst_geometry(de) |&gt; plot(add = TRUE, border = \"yellow\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Operations, raster-vector, vector-raster</span>"
    ]
  },
  {
    "objectID": "day2.html#up--and-down-scaling",
    "href": "day2.html#up--and-down-scaling",
    "title": "\n2  Operations, raster-vector, vector-raster\n",
    "section": "\n2.7 up- and down-scaling",
    "text": "2.7 up- and down-scaling\nUp- and downscaling means going from fine to course resolution (up), or from course to fine resolution (down). Upscaling is usually simple as it may simply involve grouping and summarising, downscaling is complicated as it may involve statistical modelling, sampling, simulation, quantifying and handling uncertainty.\naggregation: grouping features\n\nlibrary(sf)\ndemo(nc, ask = FALSE, echo = FALSE) # loads the nc dataset\nlibrary(dplyr)\n# \n# Attaching package: 'dplyr'\n# The following object is masked from 'package:nlme':\n# \n#     collapse\n# The following objects are masked from 'package:stats':\n# \n#     filter, lag\n# The following objects are masked from 'package:base':\n# \n#     intersect, setdiff, setequal, union\nnc |&gt; select(\"BIR74\") |&gt;\n    group_by(substr(nc$NAME, 1, 1) &lt; 'M') |&gt;\n    summarise(BIR74sum = sum(BIR74)) -&gt; res\nres\n# Simple feature collection with 2 features and 2 fields\n# Geometry type: MULTIPOLYGON\n# Dimension:     XY\n# Bounding box:  xmin: -84.3 ymin: 33.9 xmax: -75.5 ymax: 36.6\n# Geodetic CRS:  NAD27\n# # A tibble: 2 × 3\n#   `substr(nc$NAME, 1, 1) &lt; \"M\"` BIR74sum                        geom\n#   &lt;lgl&gt;                            &lt;dbl&gt;          &lt;MULTIPOLYGON [°]&gt;\n# 1 FALSE                           148652 (((-78.7 35.5, -78.5 35.7,…\n# 2 TRUE                            181310 (((-77.8 35.4, -77.8 35.3,…\nplot(res[2])\n\n\n\n\n\n\n\naggregation: spatial predicates\nPackage terra can aggregate raster data specifying the number of cells to group in each dimension:\n\nlibrary(terra)\n# terra 1.8.5\n# \n# Attaching package: 'terra'\n# The following objects are masked from 'package:spatstat.geom':\n# \n#     area, delaunay, is.empty, rescale, rotate, shift,\n#     where.max, where.min\nlibrary(stars)\nL7 = st_as_stars(L7_ETMs)\nL7.t = rast(L7)\n(at = aggregate(L7.t, c(10,20)))\n# class       : SpatRaster \n# dimensions  : 36, 18, 6  (nrow, ncol, nlyr)\n# resolution  : 570, 285  (x, y)\n# extent      : 288776, 299036, 9110501, 9120761  (xmin, xmax, ymin, ymax)\n# coord. ref. : SIRGAS 2000 / UTM zone 25S (EPSG:31985) \n# source(s)   : memory\n# names       : band1, band2, band3, band4, band5, band6 \n# min values  :  58.4,  42.7,  31.3,  11.8,  12.3,  11.4 \n# max values  : 111.8,  97.9, 107.6,  84.7, 142.2, 113.9\nplot(at)\n\n\n\n\n\n\n\nPackage stars takes a more general approach, and allows arbitrary (sf or stars) objects as aggregation predicates:\n\nset.seed(1355) # make reproducible\nbb = st_bbox(L7) |&gt; st_as_sfc()\np = st_sample(bb, 200)\nst_combine(p) |&gt; st_voronoi() |&gt; st_collection_extract(\"POLYGON\") |&gt; st_crop(bb) -&gt; v\nplot(v, col = NA, border = 'black')\n\n\n\n\n\n\naa = aggregate(L7, v, mean)\nplot(aa)\n\n\n\n\n\n\n\nsampling\nAs pointed out above, st_extract() (or terra::extract()) can be used to retrieve cell values at point locations; st_intersection() can be used to retrieve polygon (or line or point) values at a give set of point locations.\nst_sample() can be used to create sample points, in addition to uniform random sampling (on \\(R^2\\), or the sphere, \\(S^2\\)) it can also be used for stratified random, regular or Fibonacci (quasi-regular on a sphere) sampling. Further strategies are provided (and interfaced) through package spatstat (e.g. spatially clustered, or with a functionally known varying intensity).\narea-weighted interpolation, dasymetric mapping\n\nst_bbox(L7) |&gt; st_as_stars(nx = 10, ny = 10) -&gt; p\naw = st_interpolate_aw(aa, p, extensive = FALSE)\n# Warning in st_interpolate_aw.sf(st_as_sf(x), to, extensive, ...):\n# st_interpolate_aw assumes attributes are constant or uniform over\n# areas of x\nplot(aw, key.pos = 1)\n\n\n\n\n\n\n\nThis preserves the area-weighted values:\n\naa.sf = st_as_sf(aa)[1]\nsum(aa.sf[[1]] * st_area(aa.sf))\n# 7.9e+09 [m^2]\nsum(aw[[1]] * st_area(aw))\n# 7.9e+09 [m^2]\n\ndownsampling\nArea-weighted interpolation can also be used to estimate (or redistribute) values for arbitrarily smaller areas. This is however of fairly little use as constants are assigned inside larger source areas. To do better, high resolution proxies can be used to inform a higher resolution spatial pattern. E.g. to estimate population density at high resolution from administrative area summaries, high resolution land use or land cover data can be used (“dasymetric mapping”). In remote sensing, high resolution spatial low resolution temporal data (e.g. aerial photo’s) are used to downsample lower resolution high frequent data (e.g. from sattelites).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Operations, raster-vector, vector-raster</span>"
    ]
  },
  {
    "objectID": "day2.html#exercises",
    "href": "day2.html#exercises",
    "title": "\n2  Operations, raster-vector, vector-raster\n",
    "section": "\n2.8 Exercises",
    "text": "2.8 Exercises\n\nIn the first st_buffer example above, how many quad segments should be used to get the difference between the buffer area and pi smaller than 0.0001?\nWhy are the circular buffers computed in the section on spherical geometry of unequal size? Why does it become \\(100 \\pi\\) when removing the coordinate reference system, as in\n\n\nb1 |&gt; st_set_crs(NA) |&gt; st_area()\n# [1] 314\nb2 |&gt; st_set_crs(NA) |&gt; st_area()\n# [1] 314\n\n\nFrom looking at the plate carree map of the world, from which geometries can you already tell that they will be not valid when considered on the sphere?\nCheck whether this is the case using st_is_valid(). Which geometries are not valid? Can you make them valid?\nTry the area-weighted example above using extensive = TRUE. What does this mean? Which quantity is preserved now?\nTry sampling the territory of Canada (from ne_countries()) using random sampling and a sample size of 500. Plot the points along with the country outline. Are the points randomly distributed on the plot?\nIn the nc dataset, for the variables “Number of Births” and “Fraction of non-white births”, are these variables spatially extensive of intensive?\nIn the station density map shown above, what is the unit of measurement of the values shown?\nFor the NO2 concentration map shown above, compute the (multi-)polygon for which interpolated values are above 15.\n\nContinue with the exercises of SDSWR Ch 5.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Operations, raster-vector, vector-raster</span>"
    ]
  },
  {
    "objectID": "day3.html",
    "href": "day3.html",
    "title": "3  inference: spatial correlation, fitting models",
    "section": "",
    "text": "3.1 Spatial correlation for point patterns,",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>inference: spatial correlation, fitting models</span>"
    ]
  },
  {
    "objectID": "day3.html#spatial-correlation-for-geostatistical-data",
    "href": "day3.html#spatial-correlation-for-geostatistical-data",
    "title": "3  inference: spatial correlation, fitting models",
    "section": "3.2 Spatial correlation for geostatistical data",
    "text": "3.2 Spatial correlation for geostatistical data",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>inference: spatial correlation, fitting models</span>"
    ]
  },
  {
    "objectID": "day3.html#spatial-correlation-in-lattice-data",
    "href": "day3.html#spatial-correlation-in-lattice-data",
    "title": "3  inference: spatial correlation, fitting models",
    "section": "3.3 Spatial correlation in lattice data",
    "text": "3.3 Spatial correlation in lattice data",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>inference: spatial correlation, fitting models</span>"
    ]
  },
  {
    "objectID": "day3.html#fitting-regression-models-under-spatial-correlation",
    "href": "day3.html#fitting-regression-models-under-spatial-correlation",
    "title": "3  inference: spatial correlation, fitting models",
    "section": "3.4 Fitting regression models under spatial correlation",
    "text": "3.4 Fitting regression models under spatial correlation",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>inference: spatial correlation, fitting models</span>"
    ]
  },
  {
    "objectID": "day4.html",
    "href": "day4.html",
    "title": "4  prediction and simulation",
    "section": "",
    "text": "4.1 point patterns:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>prediction and simulation</span>"
    ]
  },
  {
    "objectID": "day4.html#point-patterns",
    "href": "day4.html#point-patterns",
    "title": "4  prediction and simulation",
    "section": "",
    "text": "fitting densities\n\n\nsimulating point patterns",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>prediction and simulation</span>"
    ]
  },
  {
    "objectID": "day4.html#geostatistics",
    "href": "day4.html#geostatistics",
    "title": "4  prediction and simulation",
    "section": "4.2 geostatistics",
    "text": "4.2 geostatistics\n\nkriging interpolation\n\n\nconditional simulation,",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>prediction and simulation</span>"
    ]
  }
]